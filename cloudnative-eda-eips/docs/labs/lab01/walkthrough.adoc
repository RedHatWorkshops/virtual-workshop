:walkthrough: Cloud-Native Integration with EDA & EIPs
:che-url: http://che-che.{openshift-app-host}/
:amqoneline-url: https://console-workshop-operators.{openshift-app-host}/
:user-password: openshift
:standard-fail-text: Verify that you followed all the steps. If you continue to have issues, contact a workshop assistant.

[id='cloud-native-integration']
= Cloud-Native, Event-Driven Integration with Enterprise Integration Patterns (EIPs)

In this lab you will consume IoT events from an AMQ Online topic, use Enterprise Integration Patterns (EIPs) in Camel-K to split and route messages to a Datalake.  Lastly, you'll stream the messages to a Standard and Premium Shipping topic on Kafka.

*Audience:* Enterprise Integrators, System Architects, Developers, Data Integrators

*Overview*

Enterprise Integration Patterns (EIPs) have been used in technology for 40+ years.  But are they still relevant when we attempt Cloud-Native integration?

Patterns like the Splitter, Content-Based Routing (CBR) and WireTap are still very useful when it comes to managing and integrating our data in the cloud.  Using Camel-K, we are able to enhance existing streaming technologies like Kafka to help route and mediate our data through various channels.

*Why Red Hat?*

To solve complex cloud-native integration challenges, we need to apply EIPs to manage our data and messaging needs.  Camel-K gives us a Kubernetes native EIP solution for tackling EIPs in the cloud.

By using Camel-K, we can enhance data streaming and apply traditional EIPs to solve cloud-native integration.

*Prerequisites*

This lab assumes you have successfully completed Lab 1 & 2.

*Credentials*

Your username is: `{user-username}` +
Your password is: `{user-password}`

[type=walkthroughResource]
.Che
****
* link:{che-url}/[Open Eclipse Che, window="_blank"]
****

[type=walkthroughResource]
.AMQ Online
****
* link:{amqoneline-url}/[Open AMQ Online Console, window="_blank"]
****

[type=walkthroughResource,serviceName=openshift]
.Openshift Admin Console
****
* link:{openshift-host}/[Open Openshift Admin Console, window="_blank"]
****

[time=10]
[id="Create AMQ Online Topics"]
== Create your AMQ Online Topic

*Red Hat AMQ Online* is an OpenShift-based mechanism for delivering messaging as a managed service. With Red Hat AMQ Online, administrators can configure a cloud-native, multi-tenant messaging service where developers can provision messaging using a _web console_. Multiple development teams can provision the brokers and queues from the console, *without* requiring each team to _install, configure, deploy, maintain, or patch any software_.

=== Create an Address Space

Let's create an AMQ Online **Address Space** using the AMQ Online Operator.

. Open the OpenShift Developer Console link:{openshift-host}/topology/ns/{user-username}[Topology View, window="_blank"]

. From the Project drop-down, select **{user-username}** as the project name. Click *+Add* on the left menu.
+
image::images/openshift-add.png[OpenShift +Add, role="integr8ly-img-responsive"]

. Click on the *From Catalog* option.
+
image::images/add-from-catalog.png[OpenShift +Add, role="integr8ly-img-responsive"]

. Type in `address` in the search box, and click on the *AddressSpace*:
+
image::images/catalog-addressspace.png[AddressSpace, role="integr8ly-img-responsive"]

. Click on *Create*:
+
image::images/online-create.png[Create AddressSpace, role="integr8ly-img-responsive"]

. Replace the content in the YAML editor with the following content:
+
[source,yaml,role="copypaste"]
----
apiVersion: enmasse.io/v1beta1
kind: AddressSpace
metadata:
  name: amq
spec:
  plan: standard-small
  type: standard
  endpoints:
    - name: messaging
      service: messaging
      expose:
        type: route
        routeServicePort: amqps
        routeTlsTermination: passthrough
      exports:
        - kind: ConfigMap
          name: amq-config
  authenticationService:
    name: none-authservice
----

. Click on *Create* to start the deployment
+
image::images/addressspace-detail.png[AddressSpace Definition, role="integr8ly-img-responsive"]

. The AMQ operator will check the new resource and will begin to prepare all required components.
+
[IMPORTANT]
====
Wait for the *Address Space* to deploy the infrastructure until the status changes to _Active_ and shows the *green* checkmark.
====
+
[NOTE]
====
This could take a few minutes to finish.  If it looks like taking longer, then refresh the page.
====

[type=verification]
Were you able to successfully provision the Address Space?

[type=verificationFail]
Verify that you followed each step in the procedure above. If you are still having issues, contact your administrator.

=== Create a Messaging Topic

. Click on the bricked icon on the top right side of the screen to get the consoles menu. The Messaging Console should now be available there.
+
image::images/openshift-messaging-console.png[Messaging Console, role="integr8ly-img-responsive"]

. Click on the *Log in with OpenShift* button.
+
image::images/openshift-messaging-login.png[Messaging Login, role="integr8ly-img-responsive"]

. Login using your user credentials.
+
image::images/openshift-login.png[Messaging Login, role="integr8ly-img-responsive"]

. Click in the *amq* link to show the Messaging console Overview Page.
+
image::images/addressspace-active.png[AMQ Address Space, role="integr8ly-img-responsive"]

. Click the *Create Address* button to create the topic.
+
image::images/1.1.7-create-topic.png[1.1.7-create-topic, role="integr8ly-img-responsive"]

. Enter the following details, then click *Next*:
** Name: *`mytopic`*
** Type: *topic*
** Plan: *Small Topic*
+
image::images/1.1.8-topic-details.png[1.1.8-topic-details, role="integr8ly-img-responsive"]

. Review your configuration and click on Finish
+
image::images/1.1.9-topic-details.png[1.1.9-topic-details, role="integr8ly-img-responsive"]

. Please wait a few minutes for the topic to provision.  Once the queue is provisioned, the topic name (`mytopic`) should have a green checkmark next to it.
+
image::images/1.1.10-topic-provisioned.png[1.1.10-topic-provisioned, role="integr8ly-img-responsive"]

[type=verification]
Were you able to successfully provision the topic in AMQ Online?

[type=verificationFail]
Verify that you followed each step in the procedure above. If you are still having issues, contact your administrator.

=== Determine AMQ Online hostname

. Navigate to the {openshift-host}[OpenShift Developer Console, window="_blank", id="{context}-3"] and login with your OpenShift credentials (`{user-username}` + `{user-password}`)

. Locate *Search* under *Advance*
+
image::images/1.1.11-find-search.png[1.1.11-find-search, role="integr8ly-img-responsive"]

. On the top search bar, select *service* and type to search *AddressSpace*, select the *AddressSpace* when appears in the drop down menu.
+
image::images/1.1.12-search-addressspace.png[1.1.12-search-addressspace, role="integr8ly-img-responsive"]

. Click on *amq*
+
image::images/1.1.13-addressspace-amq.png[1.1.13-addressspace-amq, role="integr8ly-img-responsive"]

. Click on tab *YAML*, and copy the *serviceHost* for later use.
+
image::images/1.1.14-serive-host-port.png[1.1.14-serive-host-port, role="integr8ly-img-responsive"]
+
[NOTE]
====
When we created the Address Space, we configure it to _export_ the connection configuration using a *ConfigMap*. This configuration is available for our microservices to inject the connecting details so we don't need to hardcode them in the code.
====

. Scroll down the page to reveal the _configmap_ details.  For this workshop, we will run all our services within the OpenShift cluster, so copy and write down only the `service.host` information.
+
image::images/addressspace-service-host.png[topics, role="integr8ly-img-responsive"]
+
[TIP]
====
You will also be able to see the _certificate_ information for connecting using the TLS endpoint under `external.host`. This is required for connections from _outside_ the OpenShift cluster.
====

*Well done!* You now have a running AMQ with your new topic called `mytopic`.

[type=verification]
Did you remember to write down the address space `service.host`?

[type=verificationFail]
{standard-fail-text}

[time=5]
[id="deploying-apache-kafka"]
== Deploying Apache Kafka on OpenShift

The AMQ Streams component uses powerful operators that simplify the deployment, configuration, management, and use of Apache Kafka on Red Hat OpenShiftÂ® Container Platform.

In this section you will learn how to start a local Kafka cluster that will represent the startup _Moon_ deployment.

. Go back to the OpenShift Developer console.

. Change back to the `{user-username}` project and click on *+Add* menu on the left side bar.
+
image:images/openshift-kafka-add.png[Add From Topology]
+
[IMPORTANT]
====
Be sure to switch back to your working `{user-username}` project
====

. Click on the *From Catalog* option.
+
image::images/add-from-catalog.png[OpenShift From Catalog, role="integr8ly-img-responsive"]

. Type in `kafka` in the search text field and then click on *Kafka*.
+
image::images/openshift-catalog-kafka.png[OpenShift Kafka, role="integr8ly-img-responsive"]

. Click on *Create* button.
+
image::images/openshift-create-kafka.png[OpenShift Kafka, role="integr8ly-img-responsive"]

. Create a `Kafka` Kubernetes Resource to define your Apache Kafka Cluster. Replace the _YAML_ editor with the following code:
+
[source,yaml,subs="attributes+"]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: moon
spec:
  entityOperator:
    topicOperator: {}
    userOperator: {}
  kafka:
    listeners:
      external:
        type: route
      plain: {}
      tls: {}
    replicas: 3
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
----

. Click on *Create* button.
+
image::images/openshift-kafka-resource.png[OpenShift Kafka Resource, role="integr8ly-img-responsive"]

. Go back to the topology view by clicking *Topology* in the left side menu
+
image:images/openshift-kafkas-list.png[Back To Topology]

. Wait for cluster to start it can take a few minutes as the operator will deploy your Kafka cluster infrastructure and related operators to manage it.
+
image:images/openshift-kafka-topology.png[Kafka Topology]

[type=verification]
Did all 3 Kafka resources (Kafka brokers, Zookeeper and Operator) startup OK?

[type=verificationFail]
Verify that you followed each step in the procedure above. If you are still having issues, contact your administrator.

[time=15]
[id="startup-che-workspace"]
== Provision Eclipse Che Workspace

. Navigate to Eclipse Che console: {che-url}[Eclipse Che, window="_blank", id="{context}-3"]

. Login to Che using your credentials (`{user-username}` and `{user-password}`).
+
image::images/1.1.2-login.png[1.1.2-login, role="integr8ly-img-responsive"]

. Click the **Play** button to open your workspace.  Give it a few minutes to provision and open.
+
image::images/2.1.3-open-workspace.png[2.1.3-open-workspace, role="integr8ly-img-responsive"]

. Once the workspace provisions, click the **Workspace** button and open the `FleurDeLune/projects/harvest/simulator` folder.
+
image::images/2.1.4-che-workspace-folder.png[2.1.4-che-workspace-folder, role="integr8ly-img-responsive"]

. Open the `edge.properties` file.  This is the *application.properties* file where all credentials are stored.  We need to update `remoteURI` for the **AMQP** endpoint.  Copy and paste the `serviceHost` you copied earlier (into a text editor) and update the `amqp://` endpoint with the correct service hostname.
+
image::images/2.1.5-edge-properties.png[2.1.5-edge-properties, role="integr8ly-img-responsive"]

. Select **Terminal > Open Terminal** in specific container** and select the container that begins with `dil-` (followed by a 5-digit alphanumeric code).  Click it and a terminal window should open.
+
image::images/2.1.6-terminal.png[2.1.6-terminal, role="integr8ly-img-responsive"]

. Navigate back to your OpenShift Admin console and click on your username in the top right-hand corner.  Click **Copy login command**, login with your credentials, then click **Display Token**. Copy the `oc login` command from this page and paste it in your terminal window.  Hit enter to login.
+
image::images/2.1.7-oc.png[2.1.7-oc, role="integr8ly-img-responsive"]

. Once you've logged into OpenShift via the CLI, run the following commands to update `edge-config` configmap.
+
[source,bash,subs="attributes+"]
----
oc project {user-username}
cd /projects/FleurDeLune/projects/harvest/simulator
oc create configmap edge-config  --from-file=edge.properties
----

. Open the `EdgeSimulator.java` file located in the *step-1-simulator* folder.  We want to create a Camel Route that fires a timer every 5 seconds, retrieves some random data, marshalls it to JSON and sends it via AMQP to your AMQ Online **mytopic**.  Copy and paste the following Camel route to your EdgeSimulator.java file:
+
[source,java,subs="attributes+"]
----
from("timer:tick?fixedRate=true&period=5000")
.choice()
    .when(simple("{{simulator.run}}"))
        .setBody(method(this, "genRandomIoTData()"))
        .marshal().json()
        .log("${body}")
        .to("amqp:topic:mytopic?subscriptionDurable=false&exchangePattern=InOnly")
    .otherwise()
        .log("Nothing send ")
;
----
+
image::images/2.1.9-edgesim.png[2.1.9-edgesim, role="integr8ly-img-responsive"]

. Try deploying and running the *EdgeSimulator* Camel-K route by executing the following command
+
[source,bash,subs="attributes+"]
----
kamel run --name edge-simulator EdgeSimulator.java  -d camel-jackson -d camel-bean  --configmap edge-config
----

. Give the deployment 2-5 minutes to run.To see the log, run the following command, and type ctrl-C/cmd-C to exit the log
+
[source,bash,subs="attributes+"]
----
kamel log edge-simulator
----

+
image::images/2.1.10-kamel-log.png[2.1.11-verify-edge-simulator, role="integr8ly-img-responsive"]

. Or you can also navigate back to the *OpenShift Developer Console* and verify the **edge-simulator** pod deployed correctly.  You can verify this by checking the Camel **timer** is firing every 5 seconds and there are no errors.

+
image::images/2.1.11-verify-edge-simulator.png[2.1.11-verify-edge-simulator, role="integr8ly-img-responsive"]

+
image::images/2.1.12-verify-edge-simulator-log.png[2.1.11-verify-edge-simulator-log, role="integr8ly-img-responsive"]

[type=verification]
Were you able to successfully deploy the Camel-K **Edge Simulator** to OpenShift?

[type=verificationFail]
Verify that you followed each step in the procedure above. If you are still having issues, contact your administrator.

[time=15]
[id="setup-order-inventory"]
== Setup Order Inventory with AMQ Streams

. Navigate to the {openshift-host}[OpenShift Developer Console, window="_blank", id="{context}-3"]

. Login to OpenShift Developer Console using your credentials (`{user-username}` and `{user-password}`).

. Select the *Developer* drop-down, then select *Project: {user-username}*, *+Add* and click on the `From Catalog` link.
+
image::images/3.1.3-add-from-catalog.png[3.1.3-add-from-catalog, role="integr8ly-img-responsive"]

. In the *Filter by keyword...* box, enter `Postgresql`, then select the **PostgreSQL (Ephemeral)** template.  Click the **Instantiate Template** button.
+
image::images/3.1.5-postgres-template.png[3.1.5-postgres-template, role="integr8ly-img-responsive"]

. Update the following template details leaving the remaining default values untouched, then click **Create**:
** PostgreSQL Connection Username: *`user`*
** PostgreSQL Connection Password: *`password`*
+
image::images/3.1.6-postgres-details.png[3.1.6-postgres-details, role="integr8ly-img-responsive"]

. Wait for the pod to deploy (30 seconds - 1 minute).  Click on *Topology* then click the `postgresql` pod.
+
image::images/3.1.7-pod-details.png[3.1.7-pod-details, role="integr8ly-img-responsive"]

. Click on the *Terminal* tab and enter the following:
+
[source,bash,subs="attributes+"]
----
psql -d sampledb -U user

CREATE TABLE premium (
	mmid bigint NOT NULL,
	diameter integer NOT NULL,
    weight decimal NOT NULL,
	created_at TIMESTAMP NOT NULL DEFAULT NOW()
);


CREATE TABLE standard (
	weight decimal NOT NULL,
	created_at TIMESTAMP NOT NULL DEFAULT NOW()
);

INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
----

. Now that we've populated the database table with records, navigate back to the *Eclipse Che* window and open the `FleurDeLune/projects/harvest/inventory` project.  Examine the `Inventory.java` file.  At this point we need to create 3 Camel routes.  A route to:
+
** Consume harvest JSON messages from AMQ Online, and using Content-based routing determine whether they are standard, premium or utility marshmallows.
** Insert premium marshmallow dimensions into the PREMIUM database table
** Insert standard marshmallow dimensions into the STANDARD database table

. Copy & paste the following Camel routes to the `Inventory.java` file:
+
[source,java,subs="attributes+"]
----
from("amqp:topic:mytopic?subscriptionDurable=false")
.split().jsonpath("$.harvest[*]")
    .choice()
        .when().jsonpath("$[?(@.diameter > 4 )]" )
            .log("Premium ${body}")
            .wireTap("direct:premiumDB")
                .newExchangeHeader("quality", constant("Premium"))
                .newExchangeHeader("diameter",jsonpath("$.diameter"))
                .newExchangeHeader("weight",jsonpath("$.weight"))
                .newExchangeHeader("mmid",jsonpath("$.mmid"))
            .end()
            .marshal().json()
            .to("kafka:{user-username}-premium?groupId=sender")
        .when().jsonpath("$[?(@.diameter > 1 )]")
            .log("Standard ${body}")
            .wireTap("direct:standardDB")
                .newExchangeHeader("quality", constant("Standard"))
                .newExchangeHeader("weight",jsonpath("$.weight"))
            .end()
            .marshal().json()
            .to("kafka:{user-username}-standard?groupId=sender")
        .otherwise()
            .log("Utility ${body}")
            .marshal().json()
            .to("kafka:{user-username}-utility?groupId=sender")
        .end()
;

from("direct:premiumDB")
    .log("inventoryDa stored ${headers.quality} diameter ${headers.diameter}")
    .setBody(simple("insert into premium (mmid,diameter,weight) VALUES (${headers.mmid},${headers.diameter},${headers.weight} )"))
    .to("jdbc:dataSource");

from("direct:standardDB")
    .log("inventoryDa stored ${headers.quality}")
    .setBody(simple("insert into standard (weight) VALUES (${headers.weight})"))
    .to("jdbc:dataSource");
----
+
image::images/3.1.8-update-inventory-java.png[3.1.8-update-inventory-java, role="integr8ly-img-responsive"]

. Return to the OpenShift Developer console, click **+Add** then click **From Catalog** link.
+
image::images/3.1.3-add-from-catalog.png[3.1.3-add-from-catalog, role="integr8ly-img-responsive"]

. In the filter box type `topic` then select **Kafka topic**.  Click **Create**.  Replace the name `my-topic` with our topic name `{user-username}-premium`, and update the cluster name to `moon`.  Click **Create**.
+
image::images/3.1.9-create-kafka-topic.png[3.1.9-create-kafka-topic, role="integr8ly-img-responsive"]

. Repleat the previous step to create `{user-username}-standard` and `{user-username}-utility` topics.

. Return to the Eclipse Che IDE and open the `kafka.properties` file located in the **step-2-inventory** folder.  Update the **remoteURI** for AMQP with the same one entered in edge.properties.  Additionally, update the **kafka.brokers** URL to be `moon-kafka-bootstrap.{user-username}.svc:9092`.
+
image::images/3.1.10-update-kafka-properties.png[3.1.10-update-kafka-properties, role="integr8ly-img-responsive"]

. Return to the *dil-* terminal and execute the following commands:
+
[source,bash,subs="attributes+"]
----
oc project {user-username}
cd /projects/FleurDeLune/projects/harvest/inventory
oc create configmap sender-config  --from-file=kafka.properties
kamel run -d mvn:org.postgresql:postgresql:42.2.10 -d camel-jdbc -d mvn:org.apache.commons:commons-dbcp2:2.7.0 --configmap sender-config Inventory.java
----

. After the Camel-K command has finished deploying, it should run via the terminal without errors.  You should see **Integration Created**.
+
image::images/3.1.11-camel-k-inventory.png[3.1.11-camel-k-inventory, role="integr8ly-img-responsive"]

. We can verify that orders are inserted into the database tables (premium and standard), by returning to the OpenShift Developer Console, selecting postgresql and clicking the running pod.
+
image::images/3.1.7-pod-details.png[3.1.7-pod-details, role="integr8ly-img-responsive"]

. Click on the *Terminal* tab and enter the following:
+
[source,bash,subs="attributes+"]
----
psql -d sampledb -U user
----
+
[source,bash,subs="attributes+"]
----
select * from standard;
----

. If the Inventory simulator worked correctly, you should see new rows inserted into the **standard** table.

[type=verification]
Were you able to successfully view records in the **standard** database table?

[type=verificationFail]
Verify that you followed each step in the procedure above. If you are still having issues, contact your administrator.

[time=10]
[id="setup-data-lake"]
== Setup Data Lake with caching

. Navigate back to the Eclipse Che console, and open `connect-secret.yaml` and `jdg-cluster.yaml` located in `/projects/harvest/shipping`.  Take a  look and notice this will be the identity secret required to setup our Infinispan cluster.
+
image::images/4.1.1-connect-secret.png[4.1.1-connect-secret, role="integr8ly-img-responsive"]

. Lets go ahead and install both the secret and Infinispan cluster (the operator is already running for us).  Via the terminal console, execute the following commands:
+
[source,bash,subs="attributes+"]
----
cd /projects/FleurDeLune/projects/harvest/shipping
oc project {user-username}
oc create -f connect-secret.yaml
oc create -f jdg-cluster.yaml
----

. Navigate back to the OpenShift Developer console, select **Topology*, then click on the `example-infinispan` container.  Verify the pod has started and is running.
+
image::images/4.1.2-check-infinispan.png[4.1.2-check-infinispan, role="integr8ly-img-responsive"]

. Via the Eclipse Che IDE, open the `premiumshipping-config.yaml` file.  Update the `kafka.brokers` and `infinispan-configuration.hosts` URL to match your environment.  The kafka broker URL you can reuse from `kafka-properties` in the `step-2-inventory` folder.  For the infinispan URL, just update the `user1` value to `{user-username}`.
+
image::images/4.1.4-premium-config.png[4.1.4-premium-config, role="integr8ly-img-responsive"]

. Via the terminal, execute the following command to deploy the config map:
+
[source,bash,subs="attributes+"]
----
oc apply -f premiumshipping-config.yaml
----

. Now that we have the config map deployed, let's take a look at `PremiumShipping.java`.  This Class contains a Camel route which consumes messages from Kafka and populates the Infinispan cache with premium shipments. Let's insert our Camel routes into this class:
+
[source,java,subs="attributes+"]
----
from("timer:cleanup?repeatCount=1")
.setHeader(InfinispanConstants.OPERATION).constant(InfinispanOperation.CLEAR)
.setHeader(InfinispanConstants.KEY).constant("premium")
.to("infinispan:default")
;


from("kafka:user1-premium?groupId=premium-shipping")
.streamCaching()
    .unmarshal(new JacksonDataFormat(Map.class))
    .log("Input --> ${body}")
    .setHeader("marshmallow").simple("${body}")
    .setHeader(InfinispanConstants.OPERATION).constant(InfinispanOperation.GET)
    .setHeader(InfinispanConstants.KEY).constant("premium")
    .to("infinispan:default")
    .setHeader(InfinispanConstants.OPERATION).constant(InfinispanOperation.PUT)
    .setHeader(InfinispanConstants.KEY).constant("premium")
    .setHeader(InfinispanConstants.VALUE).method(this, "assignShipment(${body}, ${header.marshmallow})")
    .log("${body}")
    .to("infinispan:default")

;
----
+
image::images/4.1.6-update-kafka-topic.png[4.1.6-update-kafka-topic, role="integr8ly-img-responsive"]

. We need to update the standard shipping config map.  Open up `standardshipping-config.yaml` file and update both the `kafka.brokers` and `infinispan.configuration.hosts` URLs.  You can reuse the URLs you used in the premium shipping config map.
+
image::images/4.1.7-update-standard-config.png[4.1.7-update-standard-config, role="integr8ly-img-responsive"]

. Via the terminal, execute the following command to deploy the config map:
+
[source,bash,subs="attributes+"]
----
oc apply -f standardshipping-config.yaml
----

. Now that we have the config map deployed, let's take a look at `StandardShipping.java`.  This Class contains a Camel route which consumes messages from Kafka and populates the Infinispan cache with standard shipments. Update the kafka topic name to `{user-username}-standard`.
+
image::images/4.1.8-standard-java-update.png[4.1.8-standard-java-update, role="integr8ly-img-responsive"]

. Now that we have updated all the config files and code, we need to test our Camel-K routes.  Return to the *dil-* terminal and execute the following command:
+
[source,bash,subs="attributes+"]
----
kamel run -d camel-infinispan -d camel-bean -d camel-jackson -d mvn:org.wildfly.security:wildfly-elytron:1.11.2.Final --configmap premiumshipping-config PremiumShipping.java
----

. Ensure that the Camel-K command ran without error and connections to Infinispan and Kafka were successful.  You can verify the deployment via the OpenShift Developer topology screen.  Repeat the same for the StandardShipping flow:
+
[source,bash,subs="attributes+"]
----
kamel run -d camel-infinispan -d camel-bean -d camel-jackson -d mvn:org.wildfly.security:wildfly-elytron:1.11.2.Final --configmap standardshipping-config StandardShipping.java
----

[type=verification]
Were you able to successfully execute and deploy both the Standard and Premium shipping Camel-K routes without error?

[type=verificationFail]
Verify that you followed each step in the procedure above. If you are still having issues, contact your administrator.

[time=5]
[id="setup-supply-console"]
== Create a Shipping Console

Now that we have our backend services running, we can focus on creating a Shipping Console UI.

=== Deploy RESTful Interface

.  First step is to update the `/projects/harvest/display/shippingconsole-config.yaml` config map with the correct InfiniSpan hostname.  Find  **camel.component.infinispan.configuration.hosts** and update the service to: `example-infinispan.{user-username}.svc:11222`.
+
image::images/5.1.1-config-map.png[5.1.1-config-map, role="integr8ly-img-responsive"]

. Add the config map to OpenShift using the following command (via the terminal):
+
[source,bash,subs="attributes+"]
----
cd /projects/FleurDeLune/projects/harvest/display/
oc project {user-username}
oc apply -f shippingconsole-config.yaml
----

. Now that we have the configmap updated, take a look at **ConsoleService.java**.  Notice that we use Camel RESTDsl to expose a bunch of RESTFul queries around our infinispan cache.  Let's try running this interface using the following command:
+
[source,bash,subs="attributes+"]
----
kamel run -d camel-infinispan -d camel-bean -d camel-swagger-java -d camel-jackson -d camel-undertow -d mvn:org.wildfly.security:wildfly-elytron:1.11.2.Final  --configmap shippingconsole-config ConsoleService.java --dev
----

. Now that we have the Camel-K interface running, we can view the content in our Data Lake.  First, navigate here (in a new tab) to see the Standard shipments: `http://console-service-{user-username}.{openshift-app-host}/standard`. If successful, you should see output similar to the following:
+
image::images/standard-shipping-cache-web-output.png[standard-shipping-cache-web-output, role="integr8ly-img-responsive"]

. Click here (in another tab) to verify our Premium shipments cache: `http://console-service-{user-username}.{openshift-app-host}/premium`.  You should see the following output:
+
image::images/premium-cache-web-output.png[premium-cache-web-output, role="integr8ly-img-responsive"]

[type=verification]
Were you able to successfully see output from both Standard and Premium datacache?

[type=verificationFail]
Verify that you followed each step in the procedure above. If you are still having issues, contact your administrator.

[time=10]
[id="grafana"]
== Setup Grafana Dashboard

. First of all, we need to deploy the Grafana template to our namespace.  Execute the following command via the CLI *dil-* terminal:
+
[source,bash,subs="attributes+"]
----
cd /projects/FleurDeLune/projects/harvest/display

oc apply -f grafana.yaml
----
+
[source,bash,subs="attributes+"]
----
oc expose svc grafana
----

. Now that we have Grafana running, navigate back to the OpenShift Developer console and Click on grafana in the topology.  Find *Grafana* route.
+
image::images/6.1.1-grafana-route.png[6.1.1-grafana-route, role="integr8ly-img-responsive"]

. Login to Grafana using the credentials `admin/admin`.  If prompted to change your password, set it back to `admin` again.

. Now that you are logged into Grafana, we need to create a datasource. Click the `Create your first data source link`, then select **PostgreSQL**.
+
image::images/6.1.3-select-datasource.png[6.1.3-select-datasource, role="integr8ly-img-responsive"]

. In the DataSource entry screen, enter the following:
** Name: *`SampleDB`*
** Host: *`postgresql:5432`*
** Database: *`sampledb`*
** User: *`user`*
** Password: *`password`*
** SSL Mode: *`disable`*

. Click **Save & Test**
+
image::images/6.1.4-postgres-save.png[6.1.4-postgres-save, role="integr8ly-img-responsive"]

. Click the **+** symbol then click **Import**.  Give the dashboard a name of `FleurDeLune`.  Navigate back to Eclipse Che and copy the content from `/projects/harvest/display/FleurDeLune-Dashboard.json`.  Paste the content into the Grafana JSON window then click **Load**.
+
image::images/6.1.5-load-json.png[6.1.5-load-json, role="integr8ly-img-responsive"]

. If everything has been running correctly, you should see some Marshmallow distribution and weight metrics displayed on your graph.
+
image::images/6.1.6-graph-metrics.png[6.1.6-graph-metrics, role="integr8ly-img-responsive"]

[type=verification]
Were you able to successfully view the FleurDeLune metrics?

[type=verificationFail]
Verify that you followed each step in the procedure above. If you are still having issues, contact your administrator.

[time=5]
[id="summary"]
== Summary

In this lab you exposed inventory data via RestDSL, cached data from a Data Lake using InfiniSpan, then graphed the results using live data metrics in Grafana.

Open source connectors enable integrations with your local systems landscape. Explore InfiniSpan, Camel-K, and Grafana to connect APIs and services for event-driven application architectures (EDA). Red Hat offers supported versions of these connectors via Fuse and DataGrid.

You can now proceed to link:{next-lab-url}[Lab 4].

[time=4]
[id="further-reading"]
== Notes and Further Reading

* https://www.redhat.com/en/technologies/jboss-middleware/amq[Red Hat AMQ]
* https://developers.redhat.com/topics/event-driven/connectors/[Camel & Debezium Connectors]
